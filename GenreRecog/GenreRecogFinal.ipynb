{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9eIOFSocvMnunKEJgEKwf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"f0zhrXl_fxLb","collapsed":true},"outputs":[],"source":["!pip install librosa\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import librosa\n","import numpy as np\n","import os\n","import glob\n","import logging\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["log_file = '/content/drive/MyDrive/Colab Notebooks/GenreRecog/extraction.log'\n","logging.basicConfig(\n","    filename=log_file,\n","    filemode='w',\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    level=logging.INFO,\n","    force=True\n",")\n","\n","dataset_path = \"/content/drive/MyDrive/Colab Notebooks/GenreRecog/Data/genres_original\"\n","\n","def extract_mfcc(file_path, n_mfcc=13, sr=22050):\n","    try:\n","        y, sr = librosa.load(file_path, sr=sr)\n","        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n","        mfcc = np.mean(mfcc, axis=1)\n","\n","        mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)\n","\n","        logging.info(f\"Extracted MFCCs from {file_path}\")\n","        return mfcc\n","    except Exception as e:\n","        logging.error(f\"Error extracting MFCCs from {file_path}: {e}\")\n","        return None\n","\n","def load_dataset(dataset_path):\n","    genres = os.listdir(dataset_path)\n","    data = []\n","    labels = []\n","\n","    logging.info(f\"Loading dataset from {dataset_path}\")\n","    for genre in genres:\n","        genre_path = os.path.join(dataset_path, genre)\n","        audio_files = glob.glob(os.path.join(genre_path, '*.wav'))\n","        logging.info(f\"Processing genre: {genre}\")\n","\n","        for audio_file in audio_files:\n","            mfcc = extract_mfcc(audio_file)\n","            if mfcc is not None:\n","                data.append(mfcc)\n","                labels.append(genre)\n","                logging.info(f\"Loaded {len(data)} audio files.\")\n","            else:\n","                logging.warning(f\"Skipping file {audio_file} due to MFCC extraction error.\")\n","\n","    logging.info(f\"Dataset loading complete. Total samples: {len(data)}\")\n","    return np.array(data), np.array(labels)\n","\n","X, y = load_dataset(dataset_path)\n","\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","logging.info(\"Labels encoded successfully.\")"],"metadata":{"id":"flRKLZ8qf7Lk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch torchvision\n","\n","log_file='/content/drive/MyDrive/Colab Notebooks/GenreRecog/model.log'\n","logging.basicConfig(\n","    filename=log_file,\n","    filemode='w',\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    level=logging.INFO,\n","    force=True\n",")\n","\n","class MusicGenreNN(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(MusicGenreNN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, num_classes)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.3)\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        return x\n","\n","input_size = 13\n","num_classes = len(np.unique(y_encoded))\n","\n","logging.info(f\"Input size: {input_size}, Number of classes: {num_classes}\")\n","\n","X_tensor = torch.tensor(X, dtype=torch.float32)\n","y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n","\n","logging.info(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n","logging.info(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n","\n","train_data = TensorDataset(X_train, y_train)\n","test_data = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=True)\n","\n","model = MusicGenreNN(input_dim=input_size, num_classes=num_classes)\n","\n","# Loss and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","logging.info(f\"Model architecture: {model}\")\n","logging.info(f\"Optimizer: {optimizer}\")"],"metadata":{"id":"7QG-vudpf7T4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_file='/content/drive/MyDrive/Colab Notebooks/GenreRecog/training.log'\n","logging.basicConfig(\n","    filename=log_file,\n","    filemode='w',\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    level=logging.INFO,\n","    force=True\n",")\n","num_epochs = 200\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    logging.info(f\"Starting epoch {epoch + 1}/{num_epochs}\")\n","\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","        if (i + 1) % 100 == 0:\n","            logging.info(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / (i + 1):.4f}\")\n","\n","    epoch_loss = running_loss / len(train_loader)\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n","    logging.info(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n","\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/GenreRecog/music_genre_model.pth')\n","logging.info(\"Model saved successfully\")\n","\n","logging.info(\"Training complete\")"],"metadata":{"id":"i4bs0K9ff7YS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_file='/content/drive/MyDrive/Colab Notebooks/GenreRecog/evaluation.log'\n","logging.basicConfig(\n","    filename=log_file,\n","    filemode='w',\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    level=logging.INFO,\n","    force=True\n",")\n","\n","model.eval()\n","correct = 0\n","total = 0\n","all_labels = []\n","all_predictions = []\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        all_labels.extend(labels.cpu().numpy())\n","        all_predictions.extend(predicted.cpu().numpy())\n","\n","accuracy = 100 * correct / total\n","print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n","\n","report = classification_report(all_labels, all_predictions, target_names=label_encoder.classes_)\n","logging.info(f\"Classification Report:\\n{report}\")\n","print(report)\n","\n","\n","logging.info(f\"Accuracy: {accuracy:.2f}%\")\n","logging.info(f\"Classification Report:\\n{report}\")\n"],"metadata":{"id":"GhFc7hw1f7ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#neccesary to create blank log file to force previous log file to show in Drive\n","\n","import logging\n","import os\n","\n","log_file='/content/drive/MyDrive/Colab Notebooks/GenreRecog/blank.log'\n","logging.basicConfig(\n","    filename=log_file,\n","    filemode='w',\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    level=logging.INFO,\n","    force=True\n",")"],"metadata":{"id":"d1iWsQaMf7cs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GUcejOChf7fC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bkcKLe3Rf7hp"},"execution_count":null,"outputs":[]}]}